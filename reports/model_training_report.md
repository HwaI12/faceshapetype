# 顔形状分類モデル作成

## 背景と目的
本プロジェクトの目的は、顔形状（Heart, Oblong, Oval, Round, Square）を分類する機械学習モデルを構築することである。このモデルは、ResNet152を用いて画像特徴を抽出し、主成分分析（PCA）による次元削減を経て、サポートベクターマシン（SVM）で分類を行うアプローチを採用した。

## モデル構築のプロセス

### 1. データセット
本プロジェクトで使用したデータセットは、「FaceShape-Dataset」という名前のデータセットである。このデータセットには、以下のように5つの顔形状に分類された画像が含まれる。
- Heart
- Oblong
- Oval
- Round
- Square

データセットは、`training_set`と`testing_set`に分かれており、それぞれ訓練用とテスト用の画像データを提供している。

---

### 2. 特徴量抽出
画像特徴を抽出するために、以下の手法を用いた。

#### ResNet152モデル
事前学習済みのResNet152を用い、その全結合層（FC層）をIdentityに置き換えて特徴量抽出器として使用した。このモデルは、以下のように定義した。

```python
def get_resnet_model():
    model = models.resnet152(weights=ResNet152_Weights.DEFAULT)
    model.fc = nn.Identity()
    model.eval()
    return model
```

#### 前処理
ResNet152に入力する画像データには以下の変換を施した。
- サイズを224×224ピクセルにリサイズ
- テンソルへの変換
- ImageNetの平均と標準偏差で正規化

---

### 3. データ処理
`training_set`と`testing_set`に含まれる画像に対して、以下のステップを実行した。
1. 画像をディスクから読み込む。
2. OpenCVを用いてRGB形式に変換する。
3. ResNet152を用いて特徴量を抽出する。
4. ラベルを付与し、特徴量とともに保存する。

データの読み込みと特徴抽出の結果、無効な画像（読み込みエラーや空の画像）はスキップリストに記録された。

---

### 4. 次元削減
抽出された特徴量は、非常に高次元（2048次元）であるため、PCAを用いて次元削減を行った。

#### 手順
1. 主成分分析を適用し、累積寄与率が99%以上となる最小の次元数を選定。
2. 選定した次元数で再度PCAを適用し、訓練データとテストデータを変換。

これにより、特徴量の次元数を削減し、計算負荷を軽減するとともに、モデルの汎化性能を向上させることを目指した。

---

### 5. モデル構築
分類器には、サポートベクターマシン（SVM）を使用した。SVMのハイパーパラメータ最適化には、GridSearchCVを用い、以下の探索範囲で最適なパラメータを選定した。

```python
param_grid = {
    'C': [0.1, 1, 10, 100],
    'gamma': [0.0001, 0.001, 0.01, 0.1, 1],
    'kernel': ['rbf'],
}
```

クロスバリデーションにはStratifiedKFoldを採用し、分割数は5、シャッフルを有効にした。

---

### 6. 評価
テストデータを用いてモデルの性能を評価した。以下は、テストデータでの分類結果である。

#### 精度とクラス分類レポート
- 総合精度: 45%
- 各クラスごとの精度、再現率、F1スコア:

| クラス    | Precision | Recall | F1-Score | サポート数 |
|----------|-----------|--------|----------|------------|
| Heart    | 0.45      | 0.43   | 0.44     | 200        |
| Oblong   | 0.45      | 0.52   | 0.48     | 200        |
| Oval     | 0.44      | 0.35   | 0.39     | 200        |
| Round    | 0.48      | 0.56   | 0.52     | 200        |
| Square   | 0.41      | 0.38   | 0.39     | 200        |

---

## 考察
1. **精度の低さ**  
   モデルの総合精度は45%に留まった。特に、OvalとSquareクラスでの分類性能が低かった。

2. **クラス間のバランス**  
   データセットにクラス間での偏りが存在した可能性がある。データ分布を確認し、必要に応じてデータ増強（Data Augmentation）を行うべきである。

3. **特徴量次元の影響**  
   PCAによる次元削減は効果的であったが、最適な次元数を探索する余地がある。累積寄与率99%ではなく95%に設定するなど、別の条件を試すことで性能向上が期待できる。

4. **モデル選定**  
   SVMに限定せず、他の分類器（ランダムフォレスト、ニューラルネットワークなど）を試すことで、さらなる精度向上が可能である。

---

## 今後の改善案
1. **データ拡張の実施**  
   データ不足やクラス不均衡を改善するため、ランダムクロップや回転、明度調整などのデータ拡張手法を検討する。

2. **ハイパーパラメータ探索の拡張**  
   グリッドサーチに加え、ランダムサーチやベイズ最適化を活用して、SVMのハイパーパラメータをさらに効率的に探索する。

3. **異なるモデルの導入**  
   転移学習を活用したエンドツーエンドのモデル（ResNet152の全層を活用した学習など）を試す。

4. **特徴量選択の検討**  
   PCAに加え、特定の重要特徴量のみを抽出する手法（例えば、Lassoによる特徴選択）を検討する。
